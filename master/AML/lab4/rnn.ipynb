{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a53de07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "keras.utils.set_random_seed(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aa5de43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text length:  446544\n",
      "--------------------------\n",
      "﻿the project gutenberg ebook of frankenstein; or, the modern prometheus\n",
      "    \n",
      "this ebook is for the use of anyone anywhere in the united states and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. you may copy it, give it away or re-use it under the terms\n",
      "of the project gutenberg license included with this ebook or online\n",
      "at www.gutenberg.org. if you are not located in the united states,\n",
      "you will have to check the laws of the country where you are located\n",
      "before using this ebook.\n",
      "\n",
      "title: frankenstein; or, the modern prometheus\n",
      "\n",
      "author: mary wollstonecraft shelley\n",
      "\n",
      "release date: october 1, 1993 [ebook #84]\n",
      "                most recently updated: september 8, 2025\n",
      "\n",
      "language: english\n",
      "\n",
      "credits: judith boss, christy phillips, lynn hanninen and david meltzer. html version by al haines.\n",
      "        further corrections by menno de leeuw.\n",
      "\n",
      "\n",
      "*** start of the project gutenberg ebook frankenstein; or, the modern prometheus ***\n",
      "\n",
      "frankenstein;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = 'frankenstein.txt'\n",
    "url = 'https://gutenberg.org/ebooks/84.txt.utf-8'\n",
    "\n",
    "with urllib.request.urlopen(url) as file:\n",
    "\ttext = file.read().decode('utf-8').lower()\n",
    "\n",
    "#with open(path, encoding='utf-8') as f:\n",
    "#\ttext = f.read().lower()\t\t\t# Convert everything to lowercase\n",
    "\n",
    "# Length of characters in the text\n",
    "print('Text length: ', len(text))\n",
    "print('--------------------------')\n",
    "print(text[0:1000]) # First 1000 characters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef01f4b",
   "metadata": {},
   "source": [
    "Dobbiamo convertire il testo (parole) in un insieme di numeri per permettere alla rete di gestire.\n",
    "\n",
    "### Utilizziamo One-Hot Encoding\n",
    "Per ogni carattere abbiamo un'array con la flag attiva nella posizione del character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04ee63e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars:  69\n",
      "{'\\n': 0, '\\r': 1, ' ': 2, '!': 3, '#': 4, '$': 5, '%': 6, '(': 7, ')': 8, '*': 9, ',': 10, '-': 11, '.': 12, '/': 13, '0': 14, '1': 15, '2': 16, '3': 17, '4': 18, '5': 19, '6': 20, '7': 21, '8': 22, '9': 23, ':': 24, ';': 25, '?': 26, '[': 27, ']': 28, '_': 29, 'a': 30, 'b': 31, 'c': 32, 'd': 33, 'e': 34, 'f': 35, 'g': 36, 'h': 37, 'i': 38, 'j': 39, 'k': 40, 'l': 41, 'm': 42, 'n': 43, 'o': 44, 'p': 45, 'q': 46, 'r': 47, 's': 48, 't': 49, 'u': 50, 'v': 51, 'w': 52, 'x': 53, 'y': 54, 'z': 55, 'æ': 56, 'è': 57, 'é': 58, 'ê': 59, 'ô': 60, '—': 61, '‘': 62, '’': 63, '“': 64, '”': 65, '•': 66, '™': 67, '\\ufeff': 68}\n",
      "{0: '\\n', 1: '\\r', 2: ' ', 3: '!', 4: '#', 5: '$', 6: '%', 7: '(', 8: ')', 9: '*', 10: ',', 11: '-', 12: '.', 13: '/', 14: '0', 15: '1', 16: '2', 17: '3', 18: '4', 19: '5', 20: '6', 21: '7', 22: '8', 23: '9', 24: ':', 25: ';', 26: '?', 27: '[', 28: ']', 29: '_', 30: 'a', 31: 'b', 32: 'c', 33: 'd', 34: 'e', 35: 'f', 36: 'g', 37: 'h', 38: 'i', 39: 'j', 40: 'k', 41: 'l', 42: 'm', 43: 'n', 44: 'o', 45: 'p', 46: 'q', 47: 'r', 48: 's', 49: 't', 50: 'u', 51: 'v', 52: 'w', 53: 'x', 54: 'y', 55: 'z', 56: 'æ', 57: 'è', 58: 'é', 59: 'ê', 60: 'ô', 61: '—', 62: '‘', 63: '’', 64: '“', 65: '”', 66: '•', 67: '™', 68: '\\ufeff'}\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "\n",
    "print('total chars: ', len(chars))\n",
    "\n",
    "# Dictionary to convert from chars to numbers\n",
    "char_indices = dict((c,i) for i, c in enumerate(chars))\n",
    "# Dictionary to convert from numbers to chars\n",
    "indices_chars = dict((i,c) for i, c in enumerate(chars))\n",
    "\n",
    "print(char_indices)\n",
    "print(indices_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51294273",
   "metadata": {},
   "source": [
    "### Training set perparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0192e4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number  of sentences:  111135\n",
      " ebook of frankenstein; or, the modern prometheus\n",
      "    \n",
      "thi\n",
      "s\n",
      "training set shapes:  (111135, 60, 69) (111135, 69)\n"
     ]
    }
   ],
   "source": [
    "# Dati i primi 30 caratteri di contesto prevedi quello successivo\n",
    "maxlen = 60\n",
    "step = 2\n",
    "\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "# from the beginning to about half the text\n",
    "for i in range(0, 222269, step):\n",
    "\tsentences.append(text[i: i+maxlen])\n",
    "\tnext_chars.append(text[i+maxlen])\n",
    "\n",
    "print('number  of sentences: ', len(sentences))\n",
    "\n",
    "print(sentences[11])\n",
    "print(next_chars[11])\n",
    "\n",
    "# create training set & labels\n",
    "x = np.zeros((len(sentences), maxlen, len(chars))) # 15000x30x65\n",
    "y = np.zeros((len(sentences), len(chars)))  # 15000x65\n",
    "\n",
    "# spatially organize data (matrices)\n",
    "for i, (sentence, next_char) in enumerate(zip(sentences, next_chars)):\n",
    "\tfor t, char in enumerate(sentence):\n",
    "\t\tx[i, t, char_indices[char]] = 1\n",
    "\ty[i, char_indices[next_char]] = 1\n",
    "\n",
    "print('training set shapes: ', x.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e260fb45",
   "metadata": {},
   "source": [
    "### Test Set preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb5f1ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number  of sentences:  112108\n",
      "ng days, while the preparations were going forward for\n",
      "the \n",
      "e\n",
      "training set shapes:  (112108, 60, 69) (112108, 69)\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "# from the beginning to about half the text\n",
    "for i in range(222269, len(text)-maxlen, step):\n",
    "\tsentences.append(text[i: i+maxlen])\n",
    "\tnext_chars.append(text[i+maxlen])\n",
    "\n",
    "print('number  of sentences: ', len(sentences))\n",
    "\n",
    "print(sentences[11])\n",
    "print(next_chars[11])\n",
    "\n",
    "# create training set & labels\n",
    "x_test = np.zeros((len(sentences), maxlen, len(chars)))\n",
    "y_test = np.zeros((len(sentences), len(chars)))\n",
    "\n",
    "# spatially organize data (matrices)\n",
    "for i, (sentence, next_char) in enumerate(zip(sentences, next_chars)):\n",
    "\tfor t, char in enumerate(sentence):\n",
    "\t\tx_test[i, t, char_indices[char]] = 1\n",
    "\ty_test[i, char_indices[next_char]] = 1\n",
    "\n",
    "print('training set shapes: ', x_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3068086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LambdaCallback\n",
    "import sys\n",
    "\n",
    "# We only test after the tenth epoch, because we can't expect good performances before\n",
    "def testAfterEpoch(epoch, _):\n",
    "\tif epoch < 30:\n",
    "\t\treturn\n",
    "\t\t\n",
    "\tprint()\n",
    "\tprint()\n",
    "\tprint(\"---------------------- Generating text after epoch 10\")\n",
    "\n",
    "\tstart_index = random.randint(0, len(text)-maxlen-1)\n",
    "\n",
    "\tgenerated = ''\n",
    "\tsentence = text[start_index: start_index+maxlen]\n",
    "\tgenerated += sentence\n",
    "\tprint('***** starting sentence *****')\n",
    "\tprint(sentence)\n",
    "\tprint('*****************************')\n",
    "\tsys.stdout.write(generated)\n",
    "\n",
    "\tfor i in range(200):\n",
    "\t\tx_pred = np.zeros((1, maxlen, len(chars)))\n",
    "\t\tfor t, char in enumerate(sentence):\n",
    "\t\t\tx_pred[0, t, char_indices[char]] = 1\n",
    "\t\tpreds = model.predict(x_pred, verbose=0)[0]\n",
    "\t\tnext_index = np.argmax(preds)\n",
    "\t\tnext_char = indices_chars[next_index]\n",
    "\n",
    "\t\tsentence = sentence[1:] + next_char\n",
    "\t\tsys.stdout.write(next_char)\n",
    "\t\tsys.stdout.flush()\n",
    "\tprint()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=testAfterEpoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b4c952",
   "metadata": {},
   "source": [
    "## CNN Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f8f0fe",
   "metadata": {},
   "source": [
    "### CNN Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "88c5bcd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5760</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5760</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">391,748</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m66\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m33\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5760\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5760\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m)             │       \u001b[38;5;34m391,748\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">410,564</span> (1.57 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m410,564\u001b[0m (1.57 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">410,564</span> (1.57 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m410,564\u001b[0m (1.57 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "\tkeras.Input(shape=(maxlen, len(chars),1)),\n",
    "\tlayers.Conv2D(32, kernel_size=(3,3), activation='relu'),\n",
    "\tlayers.MaxPooling2D(pool_size=(2,2)),\n",
    "\tlayers.Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "\tlayers.MaxPooling2D(pool_size=(2,2)),\n",
    "\tlayers.Flatten(),\n",
    "\tlayers.Dropout(0.5),\t\t\t\t\t\t\t# To avoid overfitting\n",
    "\tlayers.Dense(len(chars), activation=\"softmax\")  # Probability of the next character\n",
    "])\n",
    "\n",
    "optmizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optmizer, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6b8f44",
   "metadata": {},
   "source": [
    "^ none is due to the fact we don't know batch size yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d66b0c8",
   "metadata": {},
   "source": [
    "### CNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1df11700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 420ms/step - accuracy: 0.1464 - loss: 3.1205\n",
      "Epoch 2/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 434ms/step - accuracy: 0.1612 - loss: 2.9744\n",
      "Epoch 3/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 437ms/step - accuracy: 0.1757 - loss: 2.8953\n",
      "Epoch 4/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 429ms/step - accuracy: 0.1918 - loss: 2.8354\n",
      "Epoch 5/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 415ms/step - accuracy: 0.1994 - loss: 2.8057\n",
      "Epoch 6/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 402ms/step - accuracy: 0.2027 - loss: 2.7878\n",
      "Epoch 7/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 407ms/step - accuracy: 0.2050 - loss: 2.7790\n",
      "Epoch 8/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 407ms/step - accuracy: 0.2058 - loss: 2.7707\n",
      "Epoch 9/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 406ms/step - accuracy: 0.2080 - loss: 2.7660\n",
      "Epoch 10/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 401ms/step - accuracy: 0.2103 - loss: 2.7571\n",
      "Epoch 11/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - accuracy: 0.2118 - loss: 2.7577\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      " and her head rested on\n",
      "her kn\n",
      "*****************************\n",
      " and her head rested on\n",
      "her knene teeee the e the e the e the eerereeeen the e the e the eereeee the e the e the e the eerereeeen the e the e the eereeee the e the e the e the eerereeeen the e the e the eereeee the e the e the e t\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 572ms/step - accuracy: 0.2111 - loss: 2.7544\n",
      "Epoch 12/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - accuracy: 0.2142 - loss: 2.7498\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "calm ernest; i enquired more\n",
      "m\n",
      "*****************************\n",
      "calm ernest; i enquired more\n",
      "meeeeeeeeeeeeeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the \n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 565ms/step - accuracy: 0.2130 - loss: 2.7485\n",
      "Epoch 13/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - accuracy: 0.2144 - loss: 2.7469\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      " live\n",
      "to witness the cruel, mi\n",
      "*****************************\n",
      " live\n",
      "to witness the cruel, mith eethe e the e the eesee eethe e the eathe e the e the eesee eethe e the eathe e the e the eesee eethe e the eathe e the e the eesee eethe e the eathe e the e the eesee eethe e the eathe e the e the\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 569ms/step - accuracy: 0.2147 - loss: 2.7417\n",
      "Epoch 14/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404ms/step - accuracy: 0.2156 - loss: 2.7339\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "my improvements, i thought\n",
      "of \n",
      "*****************************\n",
      "my improvements, i thought\n",
      "of the ereeeeeee the ereeeeee the e the erseeee the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 556ms/step - accuracy: 0.2152 - loss: 2.7344\n",
      "Epoch 15/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414ms/step - accuracy: 0.2157 - loss: 2.7332\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "ng which the spirits of the de\n",
      "*****************************\n",
      "ng which the spirits of the dethe e the e the e the eathe e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e th\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 561ms/step - accuracy: 0.2163 - loss: 2.7314\n",
      "Epoch 16/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - accuracy: 0.2209 - loss: 2.7254\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "s, and paracelsus, the lords o\n",
      "*****************************\n",
      "s, and paracelsus, the lords outhe e the erteee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee th\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 572ms/step - accuracy: 0.2200 - loss: 2.7221\n",
      "Epoch 17/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413ms/step - accuracy: 0.2211 - loss: 2.7203\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "l to my fate.\n",
      "\n",
      "great god! if f\n",
      "*****************************\n",
      "l to my fate.\n",
      "\n",
      "great god! if feereeeeeee the eathe erteeee the ereeeeeee the eathe erteeee the ereeeeeee the eathe erteeee the ereeeeeee the eathe erteeee the ereeeeeee the eathe erteeee the ereeeeeee the eathe erteeee the ereeeee\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 561ms/step - accuracy: 0.2203 - loss: 2.7189\n",
      "Epoch 18/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429ms/step - accuracy: 0.2199 - loss: 2.7188\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "en, after nearly two days’ jou\n",
      "*****************************\n",
      "en, after nearly two days’ jouees and teeee the e the easte eesee the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e the e th\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 602ms/step - accuracy: 0.2206 - loss: 2.7159\n",
      "Epoch 19/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - accuracy: 0.2260 - loss: 2.7051\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "pended on the\n",
      "life of its crea\n",
      "*****************************\n",
      "pended on the\n",
      "life of its creatent the erseeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 600ms/step - accuracy: 0.2252 - loss: 2.7050\n",
      "Epoch 20/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - accuracy: 0.2255 - loss: 2.7040\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "y some\n",
      "law in my temperature t\n",
      "*****************************\n",
      "y some\n",
      "law in my temperature the enthe erseeeend the e seeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 634ms/step - accuracy: 0.2260 - loss: 2.6991\n",
      "Epoch 21/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step - accuracy: 0.2245 - loss: 2.6992\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "l strife? but i had suffered h\n",
      "*****************************\n",
      "l strife? but i had suffered he erteeeen the erteeees eeter eethe e the eathe erteeee the erseeeee the erteeees the e the ertoeeret the erseeeen the ereeeene the e the erseeeee the erteeeee the erteeees the e the ertoeeret the ers\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 618ms/step - accuracy: 0.2257 - loss: 2.6960\n",
      "Epoch 22/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433ms/step - accuracy: 0.2285 - loss: 2.6870\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "bited towards him the simplest\n",
      "*****************************\n",
      "bited towards him the simplesteeed the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 616ms/step - accuracy: 0.2282 - loss: 2.6877\n",
      "Epoch 23/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - accuracy: 0.2311 - loss: 2.6810\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "nt if nothing worse happen to \n",
      "*****************************\n",
      "nt if nothing worse happen to hesereeee the eathe endeeeet eetereeee the enthe e the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the erteeee the e\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 579ms/step - accuracy: 0.2305 - loss: 2.6792\n",
      "Epoch 24/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439ms/step - accuracy: 0.2319 - loss: 2.6787\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "england._\n",
      "\n",
      "july 7th, 17—.\n",
      "\n",
      "\n",
      "my\n",
      "*****************************\n",
      "england._\n",
      "\n",
      "july 7th, 17—.\n",
      "\n",
      "\n",
      "my aerer e the e the erseeee the e the e seeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 616ms/step - accuracy: 0.2315 - loss: 2.6759\n",
      "Epoch 25/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step - accuracy: 0.2327 - loss: 2.6728\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "der such circumstances i\n",
      "shoul\n",
      "*****************************\n",
      "der such circumstances i\n",
      "should terereerene the enthe   seeeeeeee the e seeeeee the e the ersee end the e sene the e seeeeeeeeeeeeee and the e the endee te the erseene the e the e seeee the e the e seeee the e the e seeee the e th\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 629ms/step - accuracy: 0.2328 - loss: 2.6701\n",
      "Epoch 26/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step - accuracy: 0.2345 - loss: 2.6663\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "ransaction.\n",
      "\n",
      "“last thursday (m\n",
      "*****************************\n",
      "ransaction.\n",
      "\n",
      "“last thursday (mereeee the ersnend the erseend the e the ersnend the erseend the e the ersnend the erseend the e the ersnend the erseend the e the ersnend the erseend the e the ersnend the erseend the e the ersnend t\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 667ms/step - accuracy: 0.2340 - loss: 2.6653\n",
      "Epoch 27/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 0.2337 - loss: 2.6641\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "alais.\n",
      "during this short voyag\n",
      "*****************************\n",
      "alais.\n",
      "during this short voyag tereree seat the ersnend the erseend the e the erseend the e the erseend the e the erseend the e the erseend the e the erseend the e the erseend the e the erseend the e the erseend the e the erseend \n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 678ms/step - accuracy: 0.2340 - loss: 2.6610\n",
      "Epoch 28/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step - accuracy: 0.2369 - loss: 2.6622\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "he\n",
      "wantonness of power and cru\n",
      "*****************************\n",
      "he\n",
      "wantonness of power and crueeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 624ms/step - accuracy: 0.2376 - loss: 2.6589\n",
      "Epoch 29/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step - accuracy: 0.2386 - loss: 2.6563\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      " this situation, but when i aw\n",
      "*****************************\n",
      " this situation, but when i awne e the ereeeeree the ereeeere and the enthe erseend the erseend the erteeeen the e the ereeee the ereeee the e the ereeee the ereeee the e the ereeee the ereeee the e the ereeee the ereeee the e the\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 627ms/step - accuracy: 0.2378 - loss: 2.6544\n",
      "Epoch 30/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444ms/step - accuracy: 0.2375 - loss: 2.6548\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "e and considerateness whenever\n",
      "*****************************\n",
      "e and considerateness wheneveree the erseend the e seeteree the erteeeee the e the ereeee the e the erseend the erseend the e seeteree the erteeeee the e the ereeee the e the erseend the erseend the e seeteree the erteeeee the e t\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 623ms/step - accuracy: 0.2384 - loss: 2.6514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b4cdb10440>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, batch_size=2048, epochs=30, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f77757",
   "metadata": {},
   "source": [
    "### Compute the performance (accuracy) on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aae2ba44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3383/3383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.2637 - loss: 2.5955\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471f066e",
   "metadata": {},
   "source": [
    "# RNN Network\n",
    "\n",
    "Change the Neural model from CNN to RNN \n",
    "- e.g. LSTM\n",
    "- more or less same amount of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f54316",
   "metadata": {},
   "source": [
    "## RNN (LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4a1c4e",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84d88fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">216,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">210,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">69</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,419</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m200\u001b[0m)        │       \u001b[38;5;34m216,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m200\u001b[0m)        │           \u001b[38;5;34m400\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m210,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │           \u001b[38;5;34m300\u001b[0m │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m69\u001b[0m)             │        \u001b[38;5;34m10,419\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">437,719</span> (1.67 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m437,719\u001b[0m (1.67 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">437,719</span> (1.67 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m437,719\u001b[0m (1.67 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "\tkeras.Input(shape=(maxlen,len(chars))),\n",
    "\tlayers.LSTM(200, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
    "\tlayers.LayerNormalization(),\n",
    "\tlayers.LSTM(150, dropout=0.2, recurrent_dropout=0.2),\n",
    "\tlayers.LayerNormalization(),\n",
    "\tlayers.Dense(len(chars), activation=\"softmax\")  # Probability of the next character\n",
    "])\n",
    "\n",
    "optmizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optmizer, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d7ab9b",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b3f2299",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.fit(x, y, batch_size=2048, epochs=30, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bf8832",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b2838291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3383/3383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 14ms/step - accuracy: 0.4843 - loss: 1.7231\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24af0e8",
   "metadata": {},
   "source": [
    "## RNN (GRU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0af624",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "20b07b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_32\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_32\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">162,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">158,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,268</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru_33 (\u001b[38;5;33mGRU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m200\u001b[0m)        │       \u001b[38;5;34m162,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m200\u001b[0m)        │           \u001b[38;5;34m800\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_34 (\u001b[38;5;33mGRU\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m158,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │           \u001b[38;5;34m600\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_32 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m68\u001b[0m)             │        \u001b[38;5;34m10,268\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">332,068</span> (1.27 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m332,068\u001b[0m (1.27 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">331,368</span> (1.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m331,368\u001b[0m (1.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">700</span> (2.73 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m700\u001b[0m (2.73 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "\tkeras.Input(shape=(maxlen,len(chars))),\n",
    "\tlayers.GRU(200, return_sequences=True),\n",
    "\tlayers.GRU(150),\n",
    "\tlayers.Dense(len(chars), activation=\"softmax\")  # Probability of the next character\n",
    "])\n",
    "\n",
    "optmizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optmizer, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f8057f",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4c628adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 484ms/step - accuracy: 0.3642 - loss: 2.3272\n",
      "Epoch 2/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 481ms/step - accuracy: 0.4561 - loss: 1.8138\n",
      "Epoch 3/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 479ms/step - accuracy: 0.4929 - loss: 1.6859\n",
      "Epoch 4/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 479ms/step - accuracy: 0.5148 - loss: 1.6041\n",
      "Epoch 5/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 478ms/step - accuracy: 0.5324 - loss: 1.5430\n",
      "Epoch 6/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 476ms/step - accuracy: 0.5452 - loss: 1.4929\n",
      "Epoch 7/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 491ms/step - accuracy: 0.5559 - loss: 1.4526\n",
      "Epoch 8/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 494ms/step - accuracy: 0.5657 - loss: 1.4157\n",
      "Epoch 9/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 494ms/step - accuracy: 0.5751 - loss: 1.3821\n",
      "Epoch 10/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 495ms/step - accuracy: 0.5826 - loss: 1.3542\n",
      "Epoch 11/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - accuracy: 0.5854 - loss: 1.3466\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "ow\n",
      "professor, would lecture up\n",
      "*****************************\n",
      "ow\n",
      "professor, would lecture up that it and the devery condemn to perceived here and the path offered the path of an endued the path of an endued the path of an endued the path of an endued the path of an endued the path of an endu\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 662ms/step - accuracy: 0.5898 - loss: 1.3288\n",
      "Epoch 12/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step - accuracy: 0.5931 - loss: 1.3217\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "ne the apparel she had worn on\n",
      "*****************************\n",
      "ne the apparel she had worn one which stood and and a learn that and the paths offered that it was a since to prove of elizabeth as a from heard that is suffered the eaths of the paths offered that it was a since to prove of eliza\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 645ms/step - accuracy: 0.5975 - loss: 1.3030\n",
      "Epoch 13/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step - accuracy: 0.5988 - loss: 1.2975\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "ceived me\n",
      "weep with bitterness\n",
      "*****************************\n",
      "ceived me\n",
      "weep with bitterness the path of enjected that i approach and repursed that i approach and repursed that i approach and repursed that i approach and repursed that i approach and repursed that i approach and repursed that\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 646ms/step - accuracy: 0.6030 - loss: 1.2808\n",
      "Epoch 14/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step - accuracy: 0.6027 - loss: 1.2802\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "onourable manner, he retreated\n",
      "*****************************\n",
      "onourable manner, he retreated the eater that instate the assuatitude. i could not that he suffeent affects of not enticate that i appe the acquicted to received the appeared to puss i had returned that i and heat! of the passory \n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 645ms/step - accuracy: 0.6082 - loss: 1.2615\n",
      "Epoch 15/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - accuracy: 0.6107 - loss: 1.2593\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "re i lay by the side of a broo\n",
      "*****************************\n",
      "re i lay by the side of a brooks of hearts of herefore fature, and they from an ast hearty.”\n",
      "\n",
      "“theseffeen had returned the peace, and her endeavour to dissed to respect as a new weet had returned the peace, and her endeavour to di\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 646ms/step - accuracy: 0.6148 - loss: 1.2419\n",
      "Epoch 16/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step - accuracy: 0.6135 - loss: 1.2388\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "hale vessel;\n",
      "finding that he w\n",
      "*****************************\n",
      "hale vessel;\n",
      "finding that he was all the earth, and the earth, and the earth, and the earth, and the earth, and the earth, and the earth, and the earth, and the earth, and the earth, and the earth, and the earth, and the earth, an\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 654ms/step - accuracy: 0.6178 - loss: 1.2229\n",
      "Epoch 17/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - accuracy: 0.6162 - loss: 1.2266\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "ntor, shall curse the sun that\n",
      "*****************************\n",
      "ntor, shall curse the sun that had returned to the more fatigue, which genevan, and the preturn and therefore deserved that had returned to the more fatigue, which genevan, and the preturn and therefore deserved that had returned \n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 645ms/step - accuracy: 0.6210 - loss: 1.2102\n",
      "Epoch 18/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step - accuracy: 0.6197 - loss: 1.2135\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "s now\n",
      "february. we accordingly\n",
      "*****************************\n",
      "s now\n",
      "february. we accordingly confessor of the path of their veilling me to bestow purposess of the path of their veilling me to bestow purposess of the path of their veilling me to bestow purposess of the path of their veilling \n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 649ms/step - accuracy: 0.6249 - loss: 1.1950\n",
      "Epoch 19/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step - accuracy: 0.6244 - loss: 1.1967\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "s to prognosticate peace, or t\n",
      "*****************************\n",
      "s to prognosticate peace, or this study of the earthanner that had not beings who and propent of the old assumments of his father forms of his father forms of his father forms of his father forms of his father forms of his father \n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 647ms/step - accuracy: 0.6298 - loss: 1.1780\n",
      "Epoch 20/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - accuracy: 0.6286 - loss: 1.1776\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      " fearless and therefore powerf\n",
      "*****************************\n",
      " fearless and therefore powerful and percused the destroyed great, and entered to respect of heart. what a few we was not the immm the receive in heart from the destroyed great, and entered to respect of heart. what a few we was n\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 647ms/step - accuracy: 0.6316 - loss: 1.1684\n",
      "Epoch 21/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step - accuracy: 0.6329 - loss: 1.1618\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "ain, with\n",
      "torches; for i could\n",
      "*****************************\n",
      "ain, with\n",
      "torches; for i could not asked the appeared to percume. i could not assusted and expressed a feelings which grew are a conceived the decided to the conceived the decured to the path of severy i am weaken and entered the \n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 644ms/step - accuracy: 0.6363 - loss: 1.1523\n",
      "Epoch 22/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step - accuracy: 0.6369 - loss: 1.1565\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "ch which at present so many mo\n",
      "*****************************\n",
      "ch which at present so many mond had been of elizabeth, whiches live that instant these are is and her endeavourity and encourded that disposed that peace them to deprot and hadnews and here is and have now watched the been in the\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 647ms/step - accuracy: 0.6418 - loss: 1.1422\n",
      "Epoch 23/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step - accuracy: 0.6369 - loss: 1.1412\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "eir union they sought the plea\n",
      "*****************************\n",
      "eir union they sought the pleasures were events which i could not fix the greatest and the peach and head every discounted perquited in the grave to despect of my early desire to destate and was expection of the peaths and percume\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 648ms/step - accuracy: 0.6414 - loss: 1.1301\n",
      "Epoch 24/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step - accuracy: 0.6373 - loss: 1.1375\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "dressed him was impressive but\n",
      "*****************************\n",
      "dressed him was impressive but the cottage, to the pretencesses, and heressed and a child had to the green dispook the pretencessest and had not allow.”\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "chapter 3\n",
      "chapter 3\n",
      "chapter 3\n",
      "chapter 3\n",
      "chapter 3\n",
      "chapter 3\n",
      "chapter 3\n",
      "cha\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 647ms/step - accuracy: 0.6417 - loss: 1.1243\n",
      "Epoch 25/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - accuracy: 0.6415 - loss: 1.1280\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "all that you mention is nothin\n",
      "*****************************\n",
      "all that you mention is nothing who had not be before the earthough her great her enting heaven perefulded that the destroy elizabeth, the latter placed her gable, and her the extremess of their objectual in the path forms of the \n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 647ms/step - accuracy: 0.6452 - loss: 1.1153\n",
      "Epoch 26/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - accuracy: 0.6450 - loss: 1.1158\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "ure that he should renew his g\n",
      "*****************************\n",
      "ure that he should renew his geneva, be the pathy opportation that the pain and heartfely little unifelt and carelur, the greatest and endeavoured to pursuit. the death of the pretence and endured. i was a convery more than\n",
      "succee\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 648ms/step - accuracy: 0.6482 - loss: 1.1048\n",
      "Epoch 27/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - accuracy: 0.6468 - loss: 1.1075\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "ne, in this painful state of m\n",
      "*****************************\n",
      "ne, in this painful state of my eart, and the pleasures were indead the suntiffel and and despair. he doobsbed, and heart, and her endeavour to prespect of the poor girl had present and endursed me and desponding and the serion of\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 647ms/step - accuracy: 0.6498 - loss: 1.0987\n",
      "Epoch 28/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - accuracy: 0.6487 - loss: 1.1005\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "ather grew worse; her time\n",
      "was\n",
      "*****************************\n",
      "ather grew worse; her time\n",
      "was and unvicent, the feether came of her powers\n",
      "on her conceived. he began to me, and the servanting to his spirits of the instated and her letulnatunatly by the earth, and endeavoured to purprosed the \n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 646ms/step - accuracy: 0.6520 - loss: 1.0919\n",
      "Epoch 29/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step - accuracy: 0.6492 - loss: 1.0978\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "llen us that would make a figu\n",
      "*****************************\n",
      "llen us that would make a figus, i spoke mucheld the earth, and had deep and deserty and perear in the present several chould attentives we the several countenance. the protersed the expect of my countenance. i had not be the same\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 646ms/step - accuracy: 0.6521 - loss: 1.0883\n",
      "Epoch 30/30\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472ms/step - accuracy: 0.6520 - loss: 1.0917\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "ou to make so great, that\n",
      "not \n",
      "*****************************\n",
      "ou to make so great, that\n",
      "not ease the professor and earther. the ideas which i had not ardered, and i replied the decure the desides of their superior that received the glitted the deaths of its if it was a new we had every ead e\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 646ms/step - accuracy: 0.6541 - loss: 1.0824\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b4ada638c0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, batch_size=2048, epochs=30, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86c4003",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f58a0de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3383/3383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 10ms/step - accuracy: 0.4747 - loss: 2.0115\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeadd064",
   "metadata": {},
   "source": [
    "\n",
    "### Submission\n",
    "The notebook + short document with model, total number of parameters, accuracy of CNN, accuracy of your RNN model\n",
    "\n",
    "\n",
    "### Can we use the model to generate text?  \n",
    "è possibile fare completion del testo facendo predirre il prossimo character per sequenze di character (30) consecutive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
