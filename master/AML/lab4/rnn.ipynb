{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a53de07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "keras.utils.set_random_seed(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6aa5de43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text length:  437431\n",
      "--------------------------\n",
      "\n",
      "\n",
      "\n",
      "letter 1\n",
      "\n",
      "_to mrs. saville, england._\n",
      "\n",
      "\n",
      "st. petersburgh, dec. 11th, 17—.\n",
      "\n",
      "\n",
      "you will rejoice to hear that no disaster has accompanied the\n",
      "commencement of an enterprise which you have regarded with such evil\n",
      "forebodings. i arrived here yesterday, and my first task is to assure\n",
      "my dear sister of my welfare and increasing confidence in the success\n",
      "of my undertaking.\n",
      "\n",
      "i am already far north of london, and as i walk in the streets of\n",
      "petersburgh, i feel a cold northern breeze play upon my cheeks, which\n",
      "braces my nerves and fills me with delight. do you understand this\n",
      "feeling? this breeze, which has travelled from the regions towards\n",
      "which i am advancing, gives me a foretaste of those icy climes.\n",
      "inspirited by this wind of promise, my daydreams become more fervent\n",
      "and vivid. i try in vain to be persuaded that the pole is the seat of\n",
      "frost and desolation; it ever presents itself to my imagination as the\n",
      "region of beauty and delight. there, margaret, the sun is for ever\n",
      "visible, its broad d\n"
     ]
    }
   ],
   "source": [
    "path = 'frankenstein.txt'\n",
    "url = 'https://gutenberg.org/ebooks/84.txt.utf-8'\n",
    "\n",
    "intro_length = 1375\n",
    "\n",
    "# with urllib.request.urlopen(url) as file:\n",
    "# \ttext = file.read().decode('utf-8').lower()\n",
    "\n",
    "with open(path, encoding='utf-8') as f:\n",
    "\ttext = f.read().lower()\t\t\t# Convert everything to lowercase\n",
    "\n",
    "text = text[intro_length:-1]\n",
    "\n",
    "# Length of characters in the text\n",
    "print('Text length: ', len(text))\n",
    "print('--------------------------')\n",
    "print(text[0:1000]) # First 1000 characters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef01f4b",
   "metadata": {},
   "source": [
    "Dobbiamo convertire il testo (parole) in un insieme di numeri per permettere alla rete di gestire.\n",
    "\n",
    "### Utilizziamo One-Hot Encoding\n",
    "Per ogni carattere abbiamo un'array con la flag attiva nella posizione del character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "04ee63e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars:  66\n",
      "{'\\n': 0, ' ': 1, '!': 2, '$': 3, '%': 4, '(': 5, ')': 6, '*': 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, ';': 23, '?': 24, '[': 25, ']': 26, '_': 27, 'a': 28, 'b': 29, 'c': 30, 'd': 31, 'e': 32, 'f': 33, 'g': 34, 'h': 35, 'i': 36, 'j': 37, 'k': 38, 'l': 39, 'm': 40, 'n': 41, 'o': 42, 'p': 43, 'q': 44, 'r': 45, 's': 46, 't': 47, 'u': 48, 'v': 49, 'w': 50, 'x': 51, 'y': 52, 'z': 53, 'æ': 54, 'è': 55, 'é': 56, 'ê': 57, 'ô': 58, '—': 59, '‘': 60, '’': 61, '“': 62, '”': 63, '•': 64, '™': 65}\n",
      "{0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '%', 5: '(', 6: ')', 7: '*', 8: ',', 9: '-', 10: '.', 11: '/', 12: '0', 13: '1', 14: '2', 15: '3', 16: '4', 17: '5', 18: '6', 19: '7', 20: '8', 21: '9', 22: ':', 23: ';', 24: '?', 25: '[', 26: ']', 27: '_', 28: 'a', 29: 'b', 30: 'c', 31: 'd', 32: 'e', 33: 'f', 34: 'g', 35: 'h', 36: 'i', 37: 'j', 38: 'k', 39: 'l', 40: 'm', 41: 'n', 42: 'o', 43: 'p', 44: 'q', 45: 'r', 46: 's', 47: 't', 48: 'u', 49: 'v', 50: 'w', 51: 'x', 52: 'y', 53: 'z', 54: 'æ', 55: 'è', 56: 'é', 57: 'ê', 58: 'ô', 59: '—', 60: '‘', 61: '’', 62: '“', 63: '”', 64: '•', 65: '™'}\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "\n",
    "print('total chars: ', len(chars))\n",
    "\n",
    "# Dictionary to convert from chars to numbers\n",
    "char_indices = dict((c,i) for i, c in enumerate(chars))\n",
    "# Dictionary to convert from numbers to chars\n",
    "indices_chars = dict((i,c) for i, c in enumerate(chars))\n",
    "\n",
    "print(char_indices)\n",
    "print(indices_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51294273",
   "metadata": {},
   "source": [
    "### Training set perparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0192e4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number  of sentences:  150000\n",
      "saville, england._\n",
      "\n",
      "\n",
      "st. peter\n",
      "s\n",
      "training set shapes:  (150000, 30, 66) (150000, 66)\n"
     ]
    }
   ],
   "source": [
    "# Dati i primi 30 caratteri di contesto prevedi quello successivo\n",
    "maxlen = 30\n",
    "step = 2\n",
    "\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "# from the beginning to about half the text\n",
    "for i in range(0, 300_000, step):\n",
    "\tsentences.append(text[i: i+maxlen])\n",
    "\tnext_chars.append(text[i+maxlen])\n",
    "\n",
    "print('number  of sentences: ', len(sentences))\n",
    "\n",
    "print(sentences[11])\n",
    "print(next_chars[11])\n",
    "\n",
    "# create training set & labels\n",
    "x = np.zeros((len(sentences), maxlen, len(chars))) # 15000x30x65\n",
    "y = np.zeros((len(sentences), len(chars)))  # 15000x65\n",
    "\n",
    "# spatially organize data (matrices)\n",
    "for i, (sentence, next_char) in enumerate(zip(sentences, next_chars)):\n",
    "\tfor t, char in enumerate(sentence):\n",
    "\t\tx[i, t, char_indices[char]] = 1\n",
    "\ty[i, char_indices[next_char]] = 1\n",
    "\n",
    "print('training set shapes: ', x.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e260fb45",
   "metadata": {},
   "source": [
    "### Test Set preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bb5f1ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number  of sentences:  68701\n",
      "ne in which i was engaged, my \n",
      "s\n",
      "training set shapes:  (68701, 30, 66) (68701, 66)\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "# from the beginning to about half the text\n",
    "for i in range(300_000, len(text)-maxlen, step):\n",
    "\tsentences.append(text[i: i+maxlen])\n",
    "\tnext_chars.append(text[i+maxlen])\n",
    "\n",
    "print('number  of sentences: ', len(sentences))\n",
    "\n",
    "print(sentences[11])\n",
    "print(next_chars[11])\n",
    "\n",
    "# create training set & labels\n",
    "x_test = np.zeros((len(sentences), maxlen, len(chars)))\n",
    "y_test = np.zeros((len(sentences), len(chars)))\n",
    "\n",
    "# spatially organize data (matrices)\n",
    "for i, (sentence, next_char) in enumerate(zip(sentences, next_chars)):\n",
    "\tfor t, char in enumerate(sentence):\n",
    "\t\tx_test[i, t, char_indices[char]] = 1\n",
    "\ty_test[i, char_indices[next_char]] = 1\n",
    "\n",
    "print('training set shapes: ', x_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a3068086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LambdaCallback\n",
    "import sys\n",
    "\n",
    "# We only test after the tenth epoch, because we can't expect good performances before\n",
    "def testAfterEpoch(epoch, _):\n",
    "\tif epoch < 29:\n",
    "\t\treturn\n",
    "\t\t\n",
    "\tprint()\n",
    "\tprint()\n",
    "\tprint(\"---------------------- Generating text after epoch 29\")\n",
    "\n",
    "\tstart_index = random.randint(0, len(text)-maxlen-1)\n",
    "\n",
    "\tgenerated = ''\n",
    "\tsentence = text[start_index: start_index+maxlen]\n",
    "\tgenerated += sentence\n",
    "\tprint('***** starting sentence *****')\n",
    "\tprint(sentence)\n",
    "\tprint('*****************************')\n",
    "\tsys.stdout.write(generated)\n",
    "\n",
    "\tfor i in range(200):\n",
    "\t\tx_pred = np.zeros((1, maxlen, len(chars)))\n",
    "\t\tfor t, char in enumerate(sentence):\n",
    "\t\t\tx_pred[0, t, char_indices[char]] = 1\n",
    "\t\tpreds = model.predict(x_pred, verbose=0)[0]\n",
    "\t\tnext_index = np.argmax(preds)\n",
    "\t\tnext_char = indices_chars[next_index]\n",
    "\n",
    "\t\tsentence = sentence[1:] + next_char\n",
    "\t\tsys.stdout.write(next_char)\n",
    "\t\tsys.stdout.flush()\n",
    "\tprint()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=testAfterEpoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b4c952",
   "metadata": {},
   "source": [
    "## CNN Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f8f0fe",
   "metadata": {},
   "source": [
    "### CNN Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "88c5bcd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5760</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5760</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">380,226</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5760\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5760\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m66\u001b[0m)             │       \u001b[38;5;34m380,226\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">399,042</span> (1.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m399,042\u001b[0m (1.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">399,042</span> (1.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m399,042\u001b[0m (1.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "\tkeras.Input(shape=(maxlen, len(chars),1)),\n",
    "\tlayers.Conv2D(32, kernel_size=(3,3), activation='relu'),\n",
    "\tlayers.MaxPooling2D(pool_size=(2,2)),\n",
    "\tlayers.Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "\tlayers.MaxPooling2D(pool_size=(2,2)),\n",
    "\tlayers.Flatten(),\n",
    "\tlayers.Dropout(0.5),\t\t\t\t\t\t\t# To avoid overfitting\n",
    "\tlayers.Dense(len(chars), activation=\"softmax\")  # Probability of the next character\n",
    "])\n",
    "\n",
    "optmizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optmizer, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6b8f44",
   "metadata": {},
   "source": [
    "^ none is due to the fact we don't know batch size yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d66b0c8",
   "metadata": {},
   "source": [
    "### CNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1df11700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 489ms/step - accuracy: 0.1477 - loss: 3.0948\n",
      "Epoch 2/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 490ms/step - accuracy: 0.1740 - loss: 2.9072\n",
      "Epoch 3/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 494ms/step - accuracy: 0.1990 - loss: 2.8060\n",
      "Epoch 4/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 525ms/step - accuracy: 0.2100 - loss: 2.7627\n",
      "Epoch 5/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 535ms/step - accuracy: 0.2159 - loss: 2.7376\n",
      "Epoch 6/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 491ms/step - accuracy: 0.2209 - loss: 2.7245\n",
      "Epoch 7/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 484ms/step - accuracy: 0.2237 - loss: 2.7098\n",
      "Epoch 8/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 488ms/step - accuracy: 0.2272 - loss: 2.7026\n",
      "Epoch 9/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 493ms/step - accuracy: 0.2299 - loss: 2.6912\n",
      "Epoch 10/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 481ms/step - accuracy: 0.2314 - loss: 2.6838\n",
      "Epoch 11/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 489ms/step - accuracy: 0.2332 - loss: 2.6774\n",
      "Epoch 12/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 480ms/step - accuracy: 0.2343 - loss: 2.6684\n",
      "Epoch 13/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 488ms/step - accuracy: 0.2366 - loss: 2.6676\n",
      "Epoch 14/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 512ms/step - accuracy: 0.2365 - loss: 2.6627\n",
      "Epoch 15/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 532ms/step - accuracy: 0.2361 - loss: 2.6604\n",
      "Epoch 16/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 538ms/step - accuracy: 0.2388 - loss: 2.6534\n",
      "Epoch 17/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 473ms/step - accuracy: 0.2394 - loss: 2.6531\n",
      "Epoch 18/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 501ms/step - accuracy: 0.2414 - loss: 2.6475\n",
      "Epoch 19/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 481ms/step - accuracy: 0.2406 - loss: 2.6470\n",
      "Epoch 20/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 487ms/step - accuracy: 0.2419 - loss: 2.6433\n",
      "Epoch 21/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 481ms/step - accuracy: 0.2411 - loss: 2.6422\n",
      "Epoch 22/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 509ms/step - accuracy: 0.2421 - loss: 2.6378\n",
      "Epoch 23/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 487ms/step - accuracy: 0.2437 - loss: 2.6362\n",
      "Epoch 24/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 485ms/step - accuracy: 0.2459 - loss: 2.6314\n",
      "Epoch 25/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 482ms/step - accuracy: 0.2454 - loss: 2.6252\n",
      "Epoch 26/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 483ms/step - accuracy: 0.2482 - loss: 2.6198\n",
      "Epoch 27/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 489ms/step - accuracy: 0.2493 - loss: 2.6165\n",
      "Epoch 28/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 493ms/step - accuracy: 0.2506 - loss: 2.6107\n",
      "Epoch 29/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 481ms/step - accuracy: 0.2506 - loss: 2.6064\n",
      "Epoch 30/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511ms/step - accuracy: 0.2544 - loss: 2.6017\n",
      "\n",
      "---------------------- Generating text after epoch 29\n",
      "***** starting sentence *****\n",
      "o be taught to associate evil \n",
      "*****************************\n",
      "o be taught to associate evil the e the and the e rourt of f the and the e the e of the e and the e rand the e rome the e and the e rere the e and the e rere the e and the e rere the e and the e rere the e and the e rere the e and\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 680ms/step - accuracy: 0.2524 - loss: 2.6040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e1995c89e0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, batch_size=2048, epochs=30, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f77757",
   "metadata": {},
   "source": [
    "### Compute the performance (accuracy) on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aae2ba44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2147/2147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.2924 - loss: 2.5230\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471f066e",
   "metadata": {},
   "source": [
    "# RNN Network\n",
    "\n",
    "Change the Neural model from CNN to RNN \n",
    "- e.g. LSTM\n",
    "- more or less same amount of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f54316",
   "metadata": {},
   "source": [
    "## RNN (LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4a1c4e",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "84d88fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">330,752</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,962</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_11 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m330,752\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m66\u001b[0m)             │        \u001b[38;5;34m16,962\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">347,714</span> (1.33 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m347,714\u001b[0m (1.33 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">347,714</span> (1.33 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m347,714\u001b[0m (1.33 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "\tkeras.Input(shape=(maxlen,len(chars))),\n",
    "\tlayers.LSTM(256, dropout=0.2, recurrent_dropout=0.2),\n",
    "\tlayers.Dense(len(chars), activation=\"softmax\")  # Probability of the next character\n",
    "])\n",
    "\n",
    "optmizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optmizer, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d7ab9b",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3b3f2299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 353ms/step - accuracy: 0.2067 - loss: 2.8411\n",
      "Epoch 2/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 341ms/step - accuracy: 0.2924 - loss: 2.4278\n",
      "Epoch 3/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 338ms/step - accuracy: 0.3376 - loss: 2.2490\n",
      "Epoch 4/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 337ms/step - accuracy: 0.3753 - loss: 2.1052\n",
      "Epoch 5/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 349ms/step - accuracy: 0.3983 - loss: 2.0161\n",
      "Epoch 6/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 349ms/step - accuracy: 0.4171 - loss: 1.9474\n",
      "Epoch 7/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 353ms/step - accuracy: 0.4327 - loss: 1.8897\n",
      "Epoch 8/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 384ms/step - accuracy: 0.4456 - loss: 1.8393\n",
      "Epoch 9/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 357ms/step - accuracy: 0.4584 - loss: 1.7952\n",
      "Epoch 10/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 369ms/step - accuracy: 0.4695 - loss: 1.7539\n",
      "Epoch 11/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 372ms/step - accuracy: 0.4780 - loss: 1.7211\n",
      "Epoch 12/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 356ms/step - accuracy: 0.4883 - loss: 1.6878\n",
      "Epoch 13/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 346ms/step - accuracy: 0.4954 - loss: 1.6614\n",
      "Epoch 14/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 336ms/step - accuracy: 0.5002 - loss: 1.6427\n",
      "Epoch 15/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 354ms/step - accuracy: 0.5080 - loss: 1.6216\n",
      "Epoch 16/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 368ms/step - accuracy: 0.5092 - loss: 1.6097\n",
      "Epoch 17/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 341ms/step - accuracy: 0.5149 - loss: 1.5904\n",
      "Epoch 18/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 343ms/step - accuracy: 0.5196 - loss: 1.5757\n",
      "Epoch 19/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 358ms/step - accuracy: 0.5220 - loss: 1.5643\n",
      "Epoch 20/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 365ms/step - accuracy: 0.5260 - loss: 1.5518\n",
      "Epoch 21/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 389ms/step - accuracy: 0.5279 - loss: 1.5425\n",
      "Epoch 22/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 392ms/step - accuracy: 0.5319 - loss: 1.5312\n",
      "Epoch 23/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 389ms/step - accuracy: 0.5329 - loss: 1.5228\n",
      "Epoch 24/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 378ms/step - accuracy: 0.5339 - loss: 1.5170\n",
      "Epoch 25/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 387ms/step - accuracy: 0.5358 - loss: 1.5104\n",
      "Epoch 26/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 377ms/step - accuracy: 0.5380 - loss: 1.5025\n",
      "Epoch 27/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 383ms/step - accuracy: 0.5406 - loss: 1.4941\n",
      "Epoch 28/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 361ms/step - accuracy: 0.5421 - loss: 1.4880\n",
      "Epoch 29/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 336ms/step - accuracy: 0.5441 - loss: 1.4826\n",
      "Epoch 30/30\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.5461 - loss: 1.4749\n",
      "\n",
      "---------------------- Generating text after epoch 29\n",
      "***** starting sentence *****\n",
      "oked\n",
      "on me as a wretch doomed \n",
      "*****************************\n",
      "oked\n",
      "on me as a wretch doomed to my father had been the strangers of the strangers of the strangers of the strangers of the strangers of the strangers of the strangers of the strangers of the strangers of the strangers of the stra\n",
      "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 474ms/step - accuracy: 0.5446 - loss: 1.4793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e18ba571d0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, batch_size=2048, epochs=30, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bf8832",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b2838291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2147/2147\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 7ms/step - accuracy: 0.5408 - loss: 1.5521\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
