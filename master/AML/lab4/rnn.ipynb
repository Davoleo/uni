{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a53de07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "keras.utils.set_random_seed(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa5de43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text length:  60063\n",
      "\n",
      "﻿the project gutenberg ebook of the twin seven-shooters\n",
      "    \n",
      "this ebook is for the use of anyone anywhere in the united states and\n",
      "most other parts of the world at no cost and with almost no restrictions\n",
      "whatsoever. you may copy it, give it away or re-use it under the terms\n",
      "of the project gutenberg license included with this ebook or online\n",
      "at www.gutenberg.org. if you are not located in the united states,\n",
      "you will have to check the laws of the country where you are located\n",
      "before using this ebook.\n",
      "\n",
      "title: the twin seven-shooters\n",
      "\n",
      "author: charles frederick manderson\n",
      "\n",
      "release date: december 1, 2025 [ebook #77379]\n",
      "\n",
      "language: english\n",
      "\n",
      "original publication: new york, ny: f. tennyson neely, 1902\n",
      "\n",
      "credits: chenzw and the online distributed proofreading team at https://www.pgdp.net (this file was produced from images generously made available by the internet archive)\n",
      "\n",
      "\n",
      "*** start of the project gutenberg ebook the twin seven-shooters ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      the twin\n",
      "      seven-shooters.\n",
      "\n",
      "  [illustratio\n"
     ]
    }
   ],
   "source": [
    "path = 'the_twin_seven_shooters.txt'\n",
    "with open(path, encoding='utf-8') as f:\n",
    "\ttext = f.read().lower()\t\t\t# Convert everything to lowercase\n",
    "\n",
    "# Length of characters in the text\n",
    "print('Text length: ', len(text))\n",
    "print('--------------------------')\n",
    "print(text[0:1000]) # First 1000 characters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef01f4b",
   "metadata": {},
   "source": [
    "Dobbiamo convertire il testo (parole) in un insieme di numeri per permettere alla rete di gestire.\n",
    "\n",
    "### Utilizziamo One-Hot Encoding\n",
    "Per ogni carattere abbiamo un'array con la flag attiva nella posizione del character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ee63e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars:  65\n",
      "{'\\n': 0, ' ': 1, '!': 2, '#': 3, '$': 4, '%': 5, '(': 6, ')': 7, '*': 8, ',': 9, '-': 10, '.': 11, '/': 12, '0': 13, '1': 14, '2': 15, '3': 16, '4': 17, '5': 18, '6': 19, '7': 20, '8': 21, '9': 22, ':': 23, ';': 24, '?': 25, '[': 26, ']': 27, '_': 28, 'a': 29, 'b': 30, 'c': 31, 'd': 32, 'e': 33, 'f': 34, 'g': 35, 'h': 36, 'i': 37, 'j': 38, 'k': 39, 'l': 40, 'm': 41, 'n': 42, 'o': 43, 'p': 44, 'q': 45, 'r': 46, 's': 47, 't': 48, 'u': 49, 'v': 50, 'w': 51, 'x': 52, 'y': 53, 'z': 54, 'é': 55, 'ê': 56, '—': 57, '‘': 58, '’': 59, '“': 60, '”': 61, '•': 62, '™': 63, '\\ufeff': 64}\n",
      "{0: '\\n', 1: ' ', 2: '!', 3: '#', 4: '$', 5: '%', 6: '(', 7: ')', 8: '*', 9: ',', 10: '-', 11: '.', 12: '/', 13: '0', 14: '1', 15: '2', 16: '3', 17: '4', 18: '5', 19: '6', 20: '7', 21: '8', 22: '9', 23: ':', 24: ';', 25: '?', 26: '[', 27: ']', 28: '_', 29: 'a', 30: 'b', 31: 'c', 32: 'd', 33: 'e', 34: 'f', 35: 'g', 36: 'h', 37: 'i', 38: 'j', 39: 'k', 40: 'l', 41: 'm', 42: 'n', 43: 'o', 44: 'p', 45: 'q', 46: 'r', 47: 's', 48: 't', 49: 'u', 50: 'v', 51: 'w', 52: 'x', 53: 'y', 54: 'z', 55: 'é', 56: 'ê', 57: '—', 58: '‘', 59: '’', 60: '“', 61: '”', 62: '•', 63: '™', 64: '\\ufeff'}\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "\n",
    "print('total chars: ', len(chars))\n",
    "\n",
    "# Dictionary to convert from chars to numbers\n",
    "char_indices = dict((c,i) for i, c in enumerate(chars))\n",
    "# Dictionary to convert from numbers to chars\n",
    "indices_chars = dict((i,c) for i, c in enumerate(chars))\n",
    "\n",
    "print(char_indices)\n",
    "print(indices_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0192e4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number  of sentences:  15000\n",
      " ebook of the twin seven-shoot\n",
      "e\n"
     ]
    }
   ],
   "source": [
    "# Dati i primi 30 caratteri prevedi quello successivo\n",
    "maxlen = 30\n",
    "step = 2\n",
    "\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "# from the beginning to about half the text\n",
    "for i in range(0, 30000, step):\n",
    "\tsentences.append(text[i: i+maxlen])\n",
    "\tnext_chars.append(text[i+maxlen])\n",
    "\n",
    "print('number  of sentences: ', len(sentences))\n",
    "\n",
    "print(sentences[11])\n",
    "print(next_chars[11])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ae1e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 30, 65)\n",
      "(15000, 65)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create training set & labels\n",
    "x = np.zeros((len(sentences), maxlen, len(chars))) # 15000x30x65\n",
    "y = np.zeros((len(sentences), len(chars)))  # 15000x65\n",
    "\n",
    "# spatially organize data (matrices)\n",
    "for i, (sentence, next_char) in enumerate(zip(sentences, next_chars)):\n",
    "\tfor t, char in enumerate(sentence):\n",
    "\t\tx[i, t, char_indices[char]] = 1\n",
    "\ty[i, char_indices[next_char]] = 1\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b4c952",
   "metadata": {},
   "source": [
    "## CNN Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88c5bcd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5376</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5376</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">349,505</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5376\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5376\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)             │       \u001b[38;5;34m349,505\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">368,321</span> (1.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m368,321\u001b[0m (1.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">368,321</span> (1.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m368,321\u001b[0m (1.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "\tkeras.Input(shape=(30,65,1)),\n",
    "\tlayers.Conv2D(32, kernel_size=(3,3), activation='relu'),\n",
    "\tlayers.MaxPooling2D(pool_size=(2,2)),\n",
    "\tlayers.Conv2D(64, kernel_size=(3,3), activation='relu'),\n",
    "\tlayers.MaxPooling2D(pool_size=(2,2)),\n",
    "\tlayers.Flatten(),\n",
    "\tlayers.Dropout(0.5),\t\t\t\t\t\t\t# To avoid overfitting\n",
    "\tlayers.Dense(len(chars), activation=\"softmax\")  # Probability of the next character\n",
    "])\n",
    "\n",
    "optmizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optmizer)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6b8f44",
   "metadata": {},
   "source": [
    "^ none is due to the fact we don't know batch size yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3068086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LambdaCallback\n",
    "import sys\n",
    "\n",
    "# We only test after the tenth epoch, because we can't expect good performances before\n",
    "def testAfterEpoch(epoch, _):\n",
    "\tif epoch < 10:\n",
    "\t\treturn\n",
    "\t\t\n",
    "\tprint()\n",
    "\tprint()\n",
    "\tprint(\"---------------------- Generating text after epoch 10\")\n",
    "\n",
    "\tstart_index = random.randint(0, len(text)-maxlen-1)\n",
    "\n",
    "\tgenerated = ''\n",
    "\tsentence = text[start_index: start_index+maxlen]\n",
    "\tgenerated += sentence\n",
    "\tprint('***** starting sentence *****')\n",
    "\tprint(sentence)\n",
    "\tprint('*****************************')\n",
    "\tsys.stdout.write(generated)\n",
    "\n",
    "\tfor i in range(200):\n",
    "\t\tx_pred = np.zeros((1, maxlen, len(chars)))\n",
    "\t\tfor t, char in enumerate(sentence):\n",
    "\t\t\tx_pred[0, t, char_indices[char]] = 1\n",
    "\t\tpreds = model.predict(x_pred, verbose=0)[0]\n",
    "\t\tnext_index = np.argmax(preds)\n",
    "\t\tnext_char = indices_chars[next_index]\n",
    "\n",
    "\t\tsentence = sentence[1:] + next_char\n",
    "\t\tsys.stdout.write(next_char)\n",
    "\t\tsys.stdout.flush()\n",
    "\tprint()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=testAfterEpoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1df11700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 538ms/step - loss: 2.4052\n",
      "Epoch 2/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 560ms/step - loss: 2.3931\n",
      "Epoch 3/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 623ms/step - loss: 2.3933\n",
      "Epoch 4/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 618ms/step - loss: 2.3854\n",
      "Epoch 5/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 575ms/step - loss: 2.3958\n",
      "Epoch 6/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 626ms/step - loss: 2.3819\n",
      "Epoch 7/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 613ms/step - loss: 2.3807\n",
      "Epoch 8/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 556ms/step - loss: 2.3883\n",
      "Epoch 9/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 535ms/step - loss: 2.3826\n",
      "Epoch 10/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 626ms/step - loss: 2.3655\n",
      "Epoch 11/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615ms/step - loss: 2.3973\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "the usually present disease,\n",
      "u\n",
      "*****************************\n",
      "the usually present disease,\n",
      "uhe eemeeeeeeeppeeeeeeeeeiiiiiipdaddsiecnd, the esteeeeeseepe the eereeeeendeeeeeeeeeeeemeesithiisiniessscndadiindnd here meet the e the ereeeetee etee eeeeeeeeeeeierereeeminiieeeand diereeint ieec pee\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step - loss: 2.3610  \n",
      "Epoch 12/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555ms/step - loss: 2.3952\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      " a few\n",
      "things that you can do \n",
      "*****************************\n",
      " a few\n",
      "things that you can do the errne cothe e tare i tn  e ee et t tt the ertre cari nond the crine the erun athe ereeeet e le eart eatin re erene the r the eithr eand d f  e erere the eeeeeree othr erereath hereleeetho eure eat\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3s/step - loss: 2.3612  \n",
      "Epoch 13/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525ms/step - loss: 2.3883\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "\n",
      "1.e.5. do not copy, display, \n",
      "*****************************\n",
      "\n",
      "1.e.5. do not copy, display,   th                                                                                                                                                                                                    \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3s/step - loss: 2.3607  \n",
      "Epoch 14/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571ms/step - loss: 2.3824\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "e not met the solicitation req\n",
      "*****************************\n",
      "e not met the solicitation reqt tont te brtat tnathe e reee teat the ereae tin theeeereeeosin oe strin the ellin the entee st tte e the e etee it tteand y  o este int gsse etee ette te e the erie erit e re erece the ereeeethe eeer\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3s/step - loss: 2.3505  \n",
      "Epoch 15/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563ms/step - loss: 2.3808\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "ers, from\n",
      "every direction, on \n",
      "*****************************\n",
      "ers, from\n",
      "every direction, on adetie ntte ectte t the eente tit e the e racs e et e eo the e rere attt of the e rees ath   e  e e  o                                                                                                  \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step - loss: 2.3459  \n",
      "Epoch 16/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 537ms/step - loss: 2.3827\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "\n",
      "events of note, are as vivid \n",
      "*****************************\n",
      "\n",
      "events of note, are as vivid o nfe reeeennnde erand theicriesndtee eiete totthe endthe catee in the eereient eeeeeeeeeethe eeiriniiiiiiiiisiesteseeittttott he erereeand ieethe eemeeense eeeereeeetheieiireri cccinnnnthe e iin nfer\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3s/step - loss: 2.3534  \n",
      "Epoch 17/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532ms/step - loss: 2.3572\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "er of a century of\n",
      "separation,\n",
      "*****************************\n",
      "er of a century of\n",
      "separation, the eand s of the eara eof uhe leand o  the eint e of the earas of the edan rt the e gae orour he ersle oat e oothe eins and d the eoner ass te the e the and t of the earin the eure of the eeuin t e \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3s/step - loss: 2.3328  \n",
      "Epoch 18/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570ms/step - loss: 2.3631\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "as the sun played upon the mus\n",
      "*****************************\n",
      "as the sun played upon the musi t ehe ttan tt e eent e re eure the e eeee tie eereeeee\n",
      "\n",
      "ie eeadd iiiiills, the erededttt tnte ont e einsr e the eitee e te                                                                            \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step - loss: 2.3363  \n",
      "Epoch 19/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step - loss: 2.3691\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "ld like brother and brother,_\n",
      "\n",
      "*****************************\n",
      "ld like brother and brother,_\n",
      "in‘s areat o  of thihing s erses the ertme tith  e the e the eitsr ofese endnse fe the camie e and d if the eare orte erof the rereeentee oure rithn nes inen the etere ttthe endeeeeteeieirensadediithi\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step - loss: 2.3322  \n",
      "Epoch 20/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 579ms/step - loss: 2.3573\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      ".\n",
      "\n",
      "                          a\n",
      "*****************************\n",
      ".\n",
      "\n",
      "                          a                                                                                                                                                                                                        \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step - loss: 2.3264  \n",
      "Epoch 21/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614ms/step - loss: 2.3249\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "tents.\n",
      "\n",
      "\n",
      "                     \n",
      "*****************************\n",
      "tents.\n",
      "\n",
      "\n",
      "                                                                                                                                                                                                                             \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step - loss: 2.3069  \n",
      "Epoch 22/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632ms/step - loss: 2.3525\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "he sight fascinates us! splend\n",
      "*****************************\n",
      "he sight fascinates us! splend the artte to the andnd rithe tite tot he ertne sttn nfe and t the e the ortr ere the entee fe the eereret the erere ccthe endne rathe ereaes the teei too othe ennde the rere atttt the ereeeensns ouan\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3s/step - loss: 2.3162  \n",
      "Epoch 23/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - loss: 2.3299\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "en and earth had come\n",
      "together\n",
      "*****************************\n",
      "en and earth had come\n",
      "togethere rars itht toth ionnnthe s me anttt too here annn uhr  iwnt the allnt the e fth hatte antnt rooe the antnt the thene the reuand t ohe rite eattsre onth eemase the e riean the eand tho athe eand the e\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3s/step - loss: 2.3063  \n",
      "Epoch 24/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586ms/step - loss: 2.3281\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "clothing to keep me warm,\n",
      "but \n",
      "*****************************\n",
      "clothing to keep me warm,\n",
      "but e te ieand nfee eu t te the e pot the erman to he eand of the ermue the eeeeeetee otme are\n",
      "theie iiald eathe eith te tine tonhe eite  cathe e fthe eere entt e rore re theeeinn the eran nt the endne ft\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3s/step - loss: 2.3018  \n",
      "Epoch 25/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 568ms/step - loss: 2.3279\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "bject.\n",
      "their motto is bear and\n",
      "*****************************\n",
      "bject.\n",
      "their motto is bear andt i to the eran ethe atte atot o he erin nd the eentee eere eortrre the ermiein sue oadh eebenee urill the eereieis oor the erteeeenini load rohe erhmieis athe e raei in the s mae oothe e the oith  ea\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step - loss: 2.3003  \n",
      "Epoch 26/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535ms/step - loss: 2.3094\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "                         unite\n",
      "*****************************\n",
      "                         unite the erst to t  f t er rfit r attcting the r tar tfe hala o of rhe earaiin sathe e me ooth                                                                                                              \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step - loss: 2.2895  \n",
      "Epoch 27/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606ms/step - loss: 2.3234\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      " roll more honored\n",
      "now for pat\n",
      "*****************************\n",
      " roll more honored\n",
      "now for pate cocrne of the ermae t e t e                                                                                                                                                                           \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3s/step - loss: 2.2951  \n",
      "Epoch 28/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515ms/step - loss: 2.3022\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "teeth tear the cartridges. we\n",
      "\n",
      "*****************************\n",
      "teeth tear the cartridges. we\n",
      "ing t e                                                                                                                                                                                                 \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 3s/step - loss: 2.2825  \n",
      "Epoch 29/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504ms/step - loss: 2.3316\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "o restrictions\n",
      "    whatsoever.\n",
      "*****************************\n",
      "o restrictions\n",
      "    whatsoever. the e tee                                                                                                                                                                                              \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3s/step - loss: 2.2959  \n",
      "Epoch 30/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557ms/step - loss: 2.2907\n",
      "\n",
      "---------------------- Generating text after epoch 10\n",
      "***** starting sentence *****\n",
      "reation\n",
      "of derivative works, r\n",
      "*****************************\n",
      "reation\n",
      "of derivative works, r astnte the etne of the earor of theeeenee o the arane of the ingn                                                                                                                                      \n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3s/step - loss: 2.2706  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x276077fed20>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, batch_size=2048, epochs=30, callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeadd064",
   "metadata": {},
   "source": [
    "### TODO : Compute the performance (accuracy) on the test set\n",
    "\n",
    "### TODO 2 : Change the Neural model from CNN to RNN (suggestion: LSTM) [more or less same amount of parameters]\n",
    "\n",
    "\n",
    "### Submission\n",
    "The notebook + short document with model, total number of parameters, accuracy of CNN, accuracy of your RNN model\n",
    "\n",
    "\n",
    "### Can we use the model to generate text?  \n",
    "è possibile fare completion del testo facendo predirre il prossimo character per sequenze di character (30) consecutive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
